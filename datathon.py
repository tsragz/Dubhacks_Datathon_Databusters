# -*- coding: utf-8 -*-
"""Datathong

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F4E0K14l_iUUhJU9n0-aF11pBKqNKxQN
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')

#filtered_df = pd.read_excel('/content/drive/MyDrive/Datathon/Drug_overdose_death_rates__by_drug_type__sex__age__race__and_Hispanic_origin__United_States_20240518.csv')
raw_df=pd.read_excel('/content/drive/MyDrive/Datathon/Drug_overdose_death_rates__by_drug_type__sex__age__race__and_Hispanic_origin__United_States_20240518.xlsx')

raw_df.info()

raw_df[raw_df['YEAR']==2016]

raw_df['ESTIMATE'].isna().sum()

raw_df_cleaned = raw_df.dropna(subset=['ESTIMATE'])

raw_df.isna().sum()

# Plot death rates for each demographic group over time
groups = raw_df_cleaned['STUB_LABEL'].unique()
for group in groups:
    group_df = raw_df_cleaned[raw_df_cleaned['STUB_LABEL'] == group]
    plt.figure(figsize=(10, 6))
    plt.plot(group_df['YEAR'], group_df['ESTIMATE'], label=group)
    plt.title(f'Death Rates over Time for {group}')
    plt.xlabel('Year')
    plt.ylabel('Death Rate')
    plt.legend()
    plt.show()

raw_df['STUB_LABEL'].unique()

from statsmodels.tsa.statespace.sarimax import SARIMAX

# Function to fit SARIMA model for a given group
def fit_sarima_model(group_df):
    # Set the index to the year
    group_df.set_index('YEAR', inplace=True)
    # Fit the model (you may need to tune the order of p, d, q)
    model = SARIMAX(group_df['ESTIMATE'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))
    results = model.fit(disp=False)
    return results

models = {}
for group in groups:
    group_df = raw_df_cleaned[raw_df_cleaned['STUB_LABEL'] == group]
    models[group] = fit_sarima_model(group_df)

# Validate the model (example: using AIC)
for group, model in models.items():
    print(f'{group}: AIC = {model.aic}')

forecast_years = [2021, 2022, 2023, 2024, 2025]

# Function to forecast future death rates
def forecast_death_rates(model, steps):
    forecast = model.get_forecast(steps=steps)
    forecast_df = forecast.conf_int()
    forecast_df['forecast'] = forecast.predicted_mean
    return forecast_df

forecasts = {}
for group in groups:
    model = models[group]
    forecasts[group] = forecast_death_rates(model, steps=len(forecast_years))

# Plot the forecasts
for group, forecast_df in forecasts.items():
    plt.figure(figsize=(10, 6))
    plt.plot(raw_df_cleaned[raw_df_cleaned['STUB_LABEL'] == group]['YEAR'], raw_df_cleaned[raw_df_cleaned['STUB_LABEL'] == group]['ESTIMATE'], label='Historical')
    plt.plot(forecast_years, forecast_df['forecast'], label='Forecast')
    plt.fill_between(forecast_years, forecast_df['lower ESTIMATE'], forecast_df['upper ESTIMATE'], color='k', alpha=0.1)
    plt.title(f'Forecasted Death Rates for {group}')
    plt.xlabel('Year')
    plt.ylabel('Death Rate')
    plt.legend()
    plt.show()

from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
import warnings
warnings.filterwarnings('ignore')

# Define feature columns and target column
X = raw_df_cleaned[['PANEL_NUM', 'UNIT_NUM', 'STUB_NAME_NUM','STUB_LABEL_NUM','YEAR_NUM','AGE_NUM']]
y = raw_df_cleaned['ESTIMATE']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize and train the XGBoost model
xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)
xgb_model.fit(X_train, y_train)

# Predict and evaluate the model
y_pred = xgb_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')

# Optional: print predicted vs actual values
print('Predicted values:', y_pred)
print('Actual values:', y_test.values)

from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestRegressor

# Suppress warnings
import warnings
warnings.filterwarnings('ignore')

# Define feature columns and target column
X = raw_df_cleaned[['PANEL_NUM', 'UNIT_NUM', 'STUB_NAME_NUM', 'STUB_LABEL_NUM', 'YEAR_NUM', 'AGE_NUM']]
y = raw_df_cleaned['ESTIMATE']

# Initialize the Random Forest model
rf_model = RandomForestRegressor(random_state=42)

# Perform cross-validation
cv_scores = cross_val_score(rf_model, X, y, cv=5, scoring='neg_mean_squared_error')
cv_rmse_scores = (-cv_scores) ** 0.5
cv_r2_scores = cross_val_score(rf_model, X, y, cv=5, scoring='r2')

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the Random Forest model
rf_model.fit(X_train, y_train)

# Predict and evaluate the model on the test set
y_pred = rf_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error on Test Set: {mse}')
print(f'R-squared on Test Set: {r2}')

# Optional: print predicted vs actual values
print('Predicted values:', y_pred)
print('Actual values:', y_test.values)



